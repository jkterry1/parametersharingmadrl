{
  "buffer_size": 100000,
  "compress_observations": true,
  "critic_hiddens": [
    256,
    256
  ],
  "env": "multiwalker",
  "gamma": 0.99,
  "learning_starts": 5000,
  "log_level": "ERROR",
  "multiagent": {
    "policies": {
      "policy_0": [
        "<class '__main__.DDPGSharedPolicy'>",
        "Box(32,)",
        "Box(4,)",
        {
          "_my_id": 0,
          "gamma": 0.99,
          "model": {
            "custom_model": "MLPModel"
          }
        }
      ],
      "policy_1": [
        "<class '__main__.DDPGSharedPolicy'>",
        "Box(32,)",
        "Box(4,)",
        {
          "_my_id": 1,
          "gamma": 0.99,
          "model": {
            "custom_model": "MLPModel"
          }
        }
      ],
      "policy_2": [
        "<class '__main__.DDPGSharedPolicy'>",
        "Box(32,)",
        "Box(4,)",
        {
          "_my_id": 2,
          "gamma": 0.99,
          "model": {
            "custom_model": "MLPModel"
          }
        }
      ]
    },
    "policy_mapping_fn": "<function <lambda> at 0x7f8f0fcde1e0>"
  },
  "num_envs_per_worker": 8,
  "num_gpus": 1,
  "num_workers": 8,
  "sample_batch_size": 20,
  "train_batch_size": 512
}