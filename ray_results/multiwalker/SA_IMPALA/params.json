{
  "clip_rewards": true,
  "compress_observations": true,
  "env": "multiwalker",
  "gamma": 0.99,
  "log_level": "ERROR",
  "lr_schedule": [
    [
      0,
      0.0005
    ],
    [
      20000000,
      1e-12
    ]
  ],
  "multiagent": {
    "policies": {
      "policy_0": [
        null,
        "Box(32,)",
        "Box(4,)",
        {
          "gamma": 0.99,
          "model": {
            "custom_model": "MLPModel"
          }
        }
      ],
      "policy_1": [
        null,
        "Box(32,)",
        "Box(4,)",
        {
          "gamma": 0.99,
          "model": {
            "custom_model": "MLPModel"
          }
        }
      ],
      "policy_2": [
        null,
        "Box(32,)",
        "Box(4,)",
        {
          "gamma": 0.99,
          "model": {
            "custom_model": "MLPModel"
          }
        }
      ]
    },
    "policy_mapping_fn": "<function <lambda> at 0x7f9302c24290>"
  },
  "num_envs_per_worker": 8,
  "num_gpus": 1,
  "num_workers": 8,
  "sample_batch_size": 20,
  "train_batch_size": 512
}