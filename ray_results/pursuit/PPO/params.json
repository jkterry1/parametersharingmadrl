{
  "batch_mode": "truncate_episodes",
  "clip_param": 0.1,
  "clip_rewards": true,
  "compress_observations": false,
  "entropy_coeff": 0.01,
  "env": "pursuit",
  "gamma": 0.99,
  "kl_coeff": 0.5,
  "lambda": 0.95,
  "log_level": "ERROR",
  "multiagent": {
    "policies": {
      "policy_0": [
        null,
        "Box(148,)",
        "Discrete(5)",
        {
          "gamma": 0.99,
          "model": {
            "custom_model": "MLPModel"
          }
        }
      ]
    },
    "policy_mapping_fn": "<function <lambda> at 0x7f8182bea400>"
  },
  "num_envs_per_worker": 8,
  "num_gpus": 1,
  "num_sgd_iter": 10,
  "num_workers": 8,
  "sample_batch_size": 100,
  "sgd_minibatch_size": 500,
  "train_batch_size": 5000,
  "vf_clip_param": 10.0,
  "vf_share_layers": true
}